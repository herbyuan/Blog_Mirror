<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>WSL开荒与机器学习环境 | H's Blog</title><meta name="author" content="Herbert"><meta name="copyright" content="Herbert"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="WSL2开荒与机器学习环境（纯新手入门向） 每次换主机或者系统重装都要进行一大堆开荒的操作，虽然操作起来流程都是一样的，但总有地方需要查。现在的网络环境下懂的不懂的人都在乱说，每次寻找信息也要花费不少时间，于是决定自己写一个文档供以后的自己参考。 WSL和WSL2 新装的系统默认的WSL应该是WSL1，如果想要更好更完整的体验可以升级到WSL2。大致来说需要的操作是在系统的 启动或关闭window">
<meta property="og:type" content="article">
<meta property="og:title" content="WSL开荒与机器学习环境">
<meta property="og:url" content="https://blog.zhuoyuan-he.cn/WSL%E5%BC%80%E8%8D%92%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83/index.html">
<meta property="og:site_name" content="H&#39;s Blog">
<meta property="og:description" content="WSL2开荒与机器学习环境（纯新手入门向） 每次换主机或者系统重装都要进行一大堆开荒的操作，虽然操作起来流程都是一样的，但总有地方需要查。现在的网络环境下懂的不懂的人都在乱说，每次寻找信息也要花费不少时间，于是决定自己写一个文档供以后的自己参考。 WSL和WSL2 新装的系统默认的WSL应该是WSL1，如果想要更好更完整的体验可以升级到WSL2。大致来说需要的操作是在系统的 启动或关闭window">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2023-03-09T15:51:20.000Z">
<meta property="article:modified_time" content="2023-04-02T04:19:43.005Z">
<meta property="article:author" content="Herbert">
<meta property="article:tag" content="WSL">
<meta name="twitter:card" content="summary"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://blog.zhuoyuan-he.cn/WSL%E5%BC%80%E8%8D%92%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: true,
    post: true
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'WSL开荒与机器学习环境',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-04-02 12:19:43'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/imgs/selfie.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">20</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">11</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">H's Blog</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">WSL开荒与机器学习环境</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-03-09T15:51:20.000Z" title="发表于 2023-03-09 23:51:20">2023-03-09</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-04-02T04:19:43.005Z" title="更新于 2023-04-02 12:19:43">2023-04-02</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="WSL开荒与机器学习环境"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1>WSL2开荒与机器学习环境（纯新手入门向）</h1>
<p>每次换主机或者系统重装都要进行一大堆开荒的操作，虽然操作起来流程都是一样的，但总有地方需要查。现在的网络环境下懂的不懂的人都在乱说，每次寻找信息也要花费不少时间，于是决定自己写一个文档供以后的自己参考。</p>
<h2 id="WSL和WSL2">WSL和WSL2</h2>
<p>新装的系统默认的WSL应该是WSL1，如果想要更好更完整的体验可以升级到WSL2。大致来说需要的操作是在系统的 <code>启动或关闭windows功能</code> 里面打开 <code>Hyper-V</code> 和 <code>适用于Linux的Windows子系统</code>。 大致来说WSL1和2的区别就是WSL2更像是一个虚拟机，它的底层和 Docker 有着千丝万缕的联系；而WSL1更像是Linux和Win的无缝衔接，这也导致了WSL1的功能和性能都在很大程度上被限制了。</p>
<p>这里再说一句网络上二者的区别。WSL1直接使用宿主机的网络，如果你在WSL1里面监听一个端口，直接使用 <code>&lt;宿主ip&gt;:&lt;监听port&gt;</code> 就可以建立连接。这样的好处就是直接可以暴露WSL里面的端口，简单方便。但是如果宿主和WSL的端口号冲突了，可想而知就会有一定的问题。而使用WSL2，默认的方式是利用 <code>hyperv</code> 建立了内部的虚拟交换机，让WSL可以访问外部的网络。但是这样外部就不能直接访问到WSL2了。解决的方式有如下两种：</p>
<p>第一种就是使用windows自带的 <code>netsh</code> <a target="_blank" rel="noopener" href="https://learn.microsoft.com/zh-tw/windows-server/networking/technologies/netsh/netsh-interface-portproxy">工具</a>做一个端口转发。 一般来说外网访问都只有ipv6的地址，2019年开始运营商网络都会支持ipv6了，如果没有ipv6地址的话排查一下老旧路由器和光猫设置应该很好解决。所以这里做一个把ipv6端口信息转发到WSL内部端口的代理：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">add v6tov6 listenport= &#123;Integer | ServiceName&#125; [[connectaddress=] &#123;IPv6Address | HostName&#125; [[connectport=] &#123;Integer | ServiceName&#125;] [[listenaddress=] &#123;IPv6Address | HostName&#125; [[protocol=]tcp]</span><br></pre></td></tr></table></figure>
<p>监听地址 <code>listenaddress</code> 如果想设置成全部地址，可以简写成 <code>::</code>，如果是ipv4就写 <code>0.0.0.0</code>，总之是全零的地址。<code>listenport</code>是在外部监听的地址，记得在防火墙里开放这个端口。<code>connectaddress</code> 是连接的地址，考虑到地址总是变来变去，这里直接用 <code>::1</code> 指定成本机就好了，<code>connectport</code> 就是希望转发到的端口。所以最后使用管理员权限运行</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">netsh interface portproxy add v6tov6 listenaddress=:: listenport=22 connectport=22 connectaddress=::1</span><br></pre></td></tr></table></figure>
<p>当然如果有很多业务放在虚拟机上，给每个端口设置转发也比较麻烦。第二个办法是直接建立外部的虚拟交换机把虚拟机加入本地网络，也获得自己的ip地址。首先搜索 <code>hyper-v管理器</code>，打开虚拟交换机管理器，新建一个外部的虚拟交换机，对应到上网的网卡，假设名字为 <code>WSLBRIDGE</code>。在windows的对应自己用户文件夹建立名为 <code>.wslconfig</code> 的文件，这是对所有WSL的全局设置。输入一下内容配置网络</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[wsl2]</span><br><span class="line">networkingMode=bridged # 桥接模式</span><br><span class="line">vmSwitch=WSLBRIDGE # 虚拟交换机名字</span><br><span class="line">ipv6=true # 启用 IPv6</span><br></pre></td></tr></table></figure>
<p>管理员权限运行 <code>wsl --shutdown &amp;&amp; wsl</code> 重启 WSL2，不出意外的话网络就是桥接模式了。 具体ip可以使用 <code>ifconfig</code> 命令查看。注意和windows不同，windows的命令是 <code>ipconfig</code>。可以使用 <code>netstat -tln</code> 查看使用中的端口。</p>
<h2 id="基本工具安装">基本工具安装</h2>
<p>闲话少说，打开虚拟化后就可以在windows商店找到 <code>Ubuntu</code>，商店提供了不同年份的LTS版本和最新的版本，在这里就使用 <code>Ubuntu 20.04.5 LTS</code>。首先拉取一下最新的文件列表：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt update</span><br><span class="line">sudo apt-get update</span><br></pre></td></tr></table></figure>
<p><code>sudo</code> 的含义是提升权限，大家都知道，在权限不够的时候加上就行，只要不是 <code>rm -rf /*</code>。本来还想写一下怎么更换国内的源的，但是最近不管是PIP，Anaconda还是 Ubuntu 的网站访问速度都还行，可能是全民数据科学的缘故，这块内容就有空再补充好了。</p>
<p>上来先无脑安装一些编译任何文件都会用到的包小试牛刀一下：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install build-essential</span><br></pre></td></tr></table></figure>
<p>这个包会安装gcc的一些东西，如果后期要自己编译一些文件可能会用到。这里先不装python了，一方面ubuntu列表里的python就像摸奖，不指定版本装出来不知道是什么玩意，另一方面反正后期用conda管理环境的话在里面装更方便。</p>
<p>接下来安装<code>Anaconda</code>。先从网上找个安装脚本然后执行：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget https://mirrors.bfsu.edu.cn/anaconda/archive/Anaconda3-2022.10-Linux-x86_64.sh --no-check-certificate</span><br><span class="line">bash Anaconda3-2021.11-Linux-x86_64.sh</span><br></pre></td></tr></table></figure>
<p>按照提示读完许可输入同意傻瓜式安装到底。最后会询问要不要初始化<code>conda</code>环境，这里建议初始化，不然可能直接敲<code>conda</code>都找不到命令。</p>
<p>安装完成之后直接输入<code>conda</code>，提示找不到命令</p>
<blockquote>
<p>conda: command not found</p>
</blockquote>
<p>不要紧张，关掉窗口重新打开就好了。或者使用命令</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> ~/.bashrc</span><br></pre></td></tr></table></figure>
<p>就可以立刻加载修改后的设置，使之生效。</p>
<p>进来之后就会发现前面多了一个 <code>(base)</code>，说明已经处在conda的环境中了。conda对比直接安装各个软件的好处就是可以创建多个虚拟环境，只要切换不同的环境就能实现不同配置的切换。</p>
<p>使用如下命令新建一个python3.9的环境</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda create -n python39 python=3.9</span><br></pre></td></tr></table></figure>
<p>通过 <code>conda activate python39</code> 切换到这个环境中来。如果想退出环境，输入 <code>conda deactivate</code> 即可。使用 <code>conda env list</code> 可以看到系统中存在的所有环境。</p>
<p>这里安装 <code>Tensorflow</code> 和 <code>Pytorch</code> 两个主流的机器学习包，并配置好 <code>CUDA</code> 和 <code>CUDNN</code> 的加速。Ubuntu本身就会带Nvidia显卡的驱动，可以使用命令 <code>nvidia-smi</code> 查看显卡的信息。首先安装 <code>CUDA</code> 和 <code>CUDNN</code>。使用 <code>conda search cudatoolkit</code> 查看可安装的版本，可以看到并不全。我的显卡是RTX3070，所以考虑使用<code>cuda11.3</code>，这也是兼容大多数包的版本。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install cudatoolkit=11.3 cudnn</span><br></pre></td></tr></table></figure>
<p>安装完成后可以继续安装 <code>Tensorflow</code> 和 <code>Pytorch</code> 。不知道为什么如果先装 <code>Pytorch</code>，安装 <code>Tensorflow</code> 时就会消耗大量的时间做冲突检查。所以在这里先安装 <code>Tensorflow</code>。注意默认情况下安装的是CPU的版本，所以要先把版本列出来选择对应的GPU版本。</p>
<p>可以看到大致信息如下</p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Version</th>
<th>Build</th>
<th>Channel</th>
</tr>
</thead>
<tbody>
<tr>
<td>tensorflow</td>
<td>2.10.0</td>
<td>eigen_py39he2aad1f_0</td>
<td>pkgs/main</td>
</tr>
<tr>
<td>tensorflow</td>
<td>2.10.0</td>
<td>gpu_py310hb074053_0</td>
<td>pkgs/main</td>
</tr>
<tr>
<td>tensorflow</td>
<td>2.10.0</td>
<td>gpu_py37h84cb581_0</td>
<td>pkgs/main</td>
</tr>
<tr>
<td>tensorflow</td>
<td>2.10.0</td>
<td>gpu_py38h11b98a5_0</td>
<td>pkgs/main</td>
</tr>
<tr>
<td>tensorflow</td>
<td>2.10.0</td>
<td>gpu_py39h039f4ff_0</td>
<td>pkgs/main</td>
</tr>
<tr>
<td>tensorflow</td>
<td>2.10.0</td>
<td>mkl_py310h24f4fea_0</td>
<td>pkgs/main</td>
</tr>
</tbody>
</table>
<p>所以不仅要指定版本号，还要指定对应的 <code>Build</code></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install tensorflow=2.10.0=gpu_py39h039f4ff_0</span><br></pre></td></tr></table></figure>
<p>安装完成后可以安装 <code>Pytorch</code>，在<a target="_blank" rel="noopener" href="https://pytorch.org/get-started/previous-versions/">官网</a>可以看到历史版本的安装指令</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install pytorch==1.11.0 torchvision==0.12.0 torchaudio==0.11.0 cudatoolkit=11.3 -c pytorch</span><br></pre></td></tr></table></figure>
<h2 id="GPU的识别与问题调试">GPU的识别与问题调试</h2>
<p>这样两个包就安装好了，接下来看一下能否识别到GPU</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">python</span><br><span class="line">&gt;&gt;&gt; import torch</span><br><span class="line">&gt;&gt;&gt; torch.cuda.is_available()</span><br><span class="line">True</span><br><span class="line">&gt;&gt;&gt; torch.cuda.get_device_name(0)</span><br><span class="line"><span class="string">&#x27;NVIDIA GeForce RTX 3070&#x27;</span></span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; import tensorflow as tf </span><br><span class="line">&gt;&gt;&gt; tf.test.is_gpu_available()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><code>Tensorflow</code> 的输出会带有很多告警信息，大致有如下几种</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">2023-03-08 18:41:43.367643: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions <span class="keyword">in</span> performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA</span><br><span class="line">To <span class="built_in">enable</span> them <span class="keyword">in</span> other operations, rebuild TensorFlow with the appropriate compiler flags.</span><br><span class="line">2023-03-08 18:41:43.450813: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, <span class="built_in">set</span> the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.</span><br><span class="line">2023-03-08 18:41:43.509932: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory <span class="keyword">for</span> plugin cuBLAS when one has already been registered</span><br><span class="line">2023-03-08 18:42:00.096412: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to <span class="built_in">read</span> NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node</span><br><span class="line">Your kernel may have been built without NUMA support.</span><br></pre></td></tr></table></figure>
<p>第一个是使用CPU的指令集，第二条是说近似计算会有些许误差，第三条直接报了 <code>ERROR</code> 说无法注册 <code>cuBLAS</code>，这应该是和内存访问有关的，官方表示是WSL系统导致的，不会对计算造成影响。最后一条 <code>NUMA</code> 也是WSL的问题，这两种信息可以不用理会，不会造成问题。</p>
<p>接下来搞一个真的要算的东西给它做做看，就用最简单的 <code>MNIST</code> 分类</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;hello world&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;step1&#x27;</span>)</span><br><span class="line"></span><br><span class="line">mnist = tf.keras.datasets.mnist</span><br><span class="line"></span><br><span class="line">(x_train, y_train), (x_test, y_test) = mnist.load_data()</span><br><span class="line">x_train, x_test = x_train / <span class="number">255.0</span>, x_test / <span class="number">255.0</span></span><br><span class="line"><span class="comment"># 搭建模型</span></span><br><span class="line">model = tf.keras.models.Sequential([tf.keras.layers.Flatten(input_shape=(<span class="number">28</span>, <span class="number">28</span>)),tf.keras.layers.Dense(<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>),tf.keras.layers.Dropout(<span class="number">0.2</span>),tf.keras.layers.Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>)])</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>,loss=<span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>,metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"><span class="comment"># 训练并验证模型</span></span><br><span class="line">model.fit(x_train, y_train, epochs=<span class="number">5</span>)</span><br></pre></td></tr></table></figure>
<p>训练一代需要大约4秒钟，这和直接跑在实体机器上的速度是相当的，说明现在WSL的性能以及N卡的虚拟化做的已经足够好了。</p>
<p>再测试一个需要用到卷积神经网络的模型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> datasets, layers, models</span><br><span class="line"></span><br><span class="line">(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Normalize pixel values to be between 0 and 1</span></span><br><span class="line">train_images, test_images = train_images / <span class="number">255.0</span>, test_images / <span class="number">255.0</span></span><br><span class="line"></span><br><span class="line">class_names = [<span class="string">&#x27;airplane&#x27;</span>, <span class="string">&#x27;automobile&#x27;</span>, <span class="string">&#x27;bird&#x27;</span>, <span class="string">&#x27;cat&#x27;</span>, <span class="string">&#x27;deer&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;frog&#x27;</span>, <span class="string">&#x27;horse&#x27;</span>, <span class="string">&#x27;ship&#x27;</span>, <span class="string">&#x27;truck&#x27;</span>]</span><br><span class="line"></span><br><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Conv2D(<span class="number">32</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>, input_shape=(<span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>)))</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line"></span><br><span class="line">model.add(layers.Flatten())</span><br><span class="line">model.add(layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">10</span>))</span><br><span class="line"></span><br><span class="line">model.summary()</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>,</span><br><span class="line">              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">history = model.fit(train_images, train_labels, epochs=<span class="number">10</span>, </span><br><span class="line">                    validation_data=(test_images, test_labels))</span><br></pre></td></tr></table></figure>
<p>在训练的一开始报出了如下信息</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Epoch 1/10</span><br><span class="line">2023-03-08 18:50:35.307252: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8201</span><br><span class="line">2023-03-08 18:50:37.047238: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory</span><br><span class="line">2023-03-08 18:50:37.138750: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory</span><br><span class="line">2023-03-08 18:50:37.138811: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn<span class="string">&#x27;t get ptxas version string: INTERNAL: Couldn&#x27;</span>t invoke ptxas --version</span><br><span class="line">2023-03-08 18:50:37.229208: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory</span><br><span class="line">2023-03-08 18:50:37.229326: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas</span><br><span class="line">Relying on driver to perform <span class="built_in">ptx</span> compilation.</span><br><span class="line">Modify <span class="variable">$PATH</span> to customize ptxas location.</span><br><span class="line">This message will be only logged once.</span><br></pre></td></tr></table></figure>
<p>这次挺幸运，模型还可以继续跑，不像上次直接就报找不到动态链接库文件了。虽然我不知道这个 <code>ptxas</code> 是个什么玩意，但是国外有大神说出现问题的原因是 <code>nvcc</code> 没有被安装进来，不信你看</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">~$ nvcc -V</span><br><span class="line">Command <span class="string">&#x27;nvcc&#x27;</span> not found, but can be installed with:</span><br><span class="line">sudo apt install nvidia-cuda-toolkit</span><br></pre></td></tr></table></figure>
<p>使用如下命令安装nvcc</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install -c nvidia cuda-nvcc</span><br></pre></td></tr></table></figure>
<p>安装完后再测试就不会有问题了。但是这里有一点很奇怪，就是如果我直接在系统里面安装官方的 CUDA 和 CUDNN，<code>nvcc</code> 识别到的就是正确的CUDA版本，但是这样安装显示的就是显卡支持的最高版本了。</p>
<p>虽然如此，无伤大雅，现在基本上机器学习最基本的环境就构建好了。</p>
<hr>
<p>好了吗，不一定，前面说的根本不能跑的问题还没说呢。</p>
<p>在 <code>Ubuntu 22.04</code> 上执行的时候，会在训练开始前跳出如下信息</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Could not load library libcudnn_cnn_infer.so.8. Error: libcuda.so: cannot open shared object file: No such file or directory</span><br><span class="line">Please make sure libcudnn_cnn_infer.so.8 is <span class="keyword">in</span> your library path!</span><br><span class="line">Aborted</span><br></pre></td></tr></table></figure>
<p>这里显示链接库中找不到文件 <code>libcudnn_cnn_infer.so.8</code>。很自然的我们要看看这个文件到底有没有。Anaconda的所有文件存放在<code>~/anaconda3/envs/&#123;myenv&#125;</code> 中，只要查看里面的 <code>/lib</code> 文件夹有没有东西就好了。但是很奇怪，这里明明白白放着一个相同命名的可执行文件。所有的网上资料都很少提及可行的解决方案，大致意思就是说既然是链接那么动态链接库的目录就应该有这个文件夹，把这个文件夹加入到 <code>$PATH</code> 和 <code>$LD_LIBRARY_PATH</code> 就可以了。那不妨我们来尝试一下</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> LD_LIBRARY_PATH=<span class="variable">$LD_LIBRARY_PATH</span>:~/anaconda3/envs/python39/lib</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:~/anaconda3/envs/python39/lib</span><br></pre></td></tr></table></figure>
<p>export 的意思是立即修改环境变量，但是重启之后就变回去了。但是没关系，因为。。。</p>
<p>这根本就没有用！！！</p>
<p>其实道理很好理解，Anaconda 把所有的可执行文件和链接库都放在以环境命名的文件夹里面了。作为一个开发软件的人不会蠢到不把这玩意加入到环境变量中，不然我还要什么虚拟环境，我自己去修改环境变量不就好了。问题的根源在于 <code>libcuda.so</code>，这玩意的链接出了点问题。如果你也有这个问题，不妨跟我一起操作下：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ sudo ldconfig</span><br><span class="line">/usr/lib/wsl/lib/libcuda.so.1 is not a symbolic <span class="built_in">link</span></span><br><span class="line"></span><br><span class="line">$ sudo <span class="built_in">rm</span> -r libcuda.so.1</span><br><span class="line">$ sudo <span class="built_in">rm</span> -r libcuda.so</span><br><span class="line"></span><br><span class="line">$ sudo <span class="built_in">ln</span> -s libcuda.so.1.1 libcuda.so.1</span><br><span class="line">$ sudo <span class="built_in">ln</span> -s libcuda.so.1.1 libcuda.so</span><br><span class="line">$ sudo sudo ldconfig</span><br></pre></td></tr></table></figure>
<p><code>ldconfig</code> 是一个动态链接库管理命令，命令的用途主要是在默认搜寻目录(<code>/lib</code> 和 <code>/usr/lib</code>)以及动态库配置文件 <code>/etc/ld.so.conf</code> 内所列的目录下搜索出可共享的动态链接库(格式如前介绍，<code>lib*.so*</code>),进而创建出动态装入程序(<code>ld.so</code>)所需的连接和缓存文件.缓存文件默认为 <code>/etc/ld.so.cache</code>，此文件保存已排好序的动态链接库名字列表。</p>
<p>然后再运行代码，发现错误已经消除了。网上的评论说这个问题只在使用 <code>Ubuntu22.04</code> 才出现，所以链接没处理好应该也是系统的问题。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://blog.zhuoyuan-he.cn">Herbert</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://blog.zhuoyuan-he.cn/WSL%E5%BC%80%E8%8D%92%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83/">https://blog.zhuoyuan-he.cn/WSL开荒与机器学习环境/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://blog.zhuoyuan-he.cn" target="_blank">H's Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/WSL/">WSL</a></div><div class="post_share"><div class="social-share" data-image="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/%E5%8D%9A%E5%BC%88%E8%AE%BA%E4%B8%8E%E7%BA%B3%E4%BB%80%E5%9D%87%E8%A1%A1/"><img class="prev-cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="onerror=null;src='/imgs/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">博弈论与纳什均衡</div></div></a></div><div class="next-post pull-right"><a href="/ICS05-Shelllab/"><img class="next-cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="onerror=null;src='/imgs/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">ICS05 Shelllab</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/imgs/selfie.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Herbert</div><div class="author-info__description">A soul discarded</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">20</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">11</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/herbyuan"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/herbyuan" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:herbyuan@icloud.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">Eventually you come...</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">WSL2开荒与机器学习环境（纯新手入门向）</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#WSL%E5%92%8CWSL2"><span class="toc-number">1.1.</span> <span class="toc-text">WSL和WSL2</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E5%B7%A5%E5%85%B7%E5%AE%89%E8%A3%85"><span class="toc-number">1.2.</span> <span class="toc-text">基本工具安装</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#GPU%E7%9A%84%E8%AF%86%E5%88%AB%E4%B8%8E%E9%97%AE%E9%A2%98%E8%B0%83%E8%AF%95"><span class="toc-number">1.3.</span> <span class="toc-text">GPU的识别与问题调试</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/Windows%E4%B8%8BWebhook%E8%B0%83%E7%94%A8PHP%E5%AE%9E%E7%8E%B0%E7%BD%91%E7%AB%99%E8%87%AA%E5%8A%A8%E9%83%A8%E7%BD%B2/" title="Windows下Webhook调用PHP实现网站自动部署">Windows下Webhook调用PHP实现网站自动部署</a><time datetime="2023-04-02T13:15:51.000Z" title="发表于 2023-04-02 21:15:51">2023-04-02</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/hello-world/" title="Hello World">Hello World</a><time datetime="2023-04-02T04:19:43.005Z" title="发表于 2023-04-02 12:19:43">2023-04-02</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/%E4%BD%BF%E7%94%A8CloudFlare%E4%BB%A3%E7%90%86%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99/" title="使用CloudFlare代理个人网站">使用CloudFlare代理个人网站</a><time datetime="2023-04-01T13:04:16.000Z" title="发表于 2023-04-01 21:04:16">2023-04-01</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/%E5%8D%95%E7%BA%AF%E5%BD%A2%E6%B3%95%E6%B1%82%E8%A7%A3%E7%BA%BF%E6%80%A7%E8%A7%84%E5%88%92/" title="单纯形法求解线性规划">单纯形法求解线性规划</a><time datetime="2023-03-27T15:04:16.000Z" title="发表于 2023-03-27 23:04:16">2023-03-27</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/%E6%B1%82%E8%A7%A3%E7%BA%B3%E4%BB%80%E5%9D%87%E8%A1%A1%E7%82%B9/" title="求解纳什均衡点（未完成）">求解纳什均衡点（未完成）</a><time datetime="2023-03-25T15:09:17.000Z" title="发表于 2023-03-25 23:09:17">2023-03-25</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By Herbert</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js"></script><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', { class: 'katex-wrap'})
  })
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>